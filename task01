#下面的笔记基于周志华老师的西瓜书以及周老师的bilibili机器学习初步课程（https://www.bilibili.com/video/BV1F2moYRERj?spm_id_from=333.788.videopod.episodes&p=13）：

##问题：
基于神经网络的连接主义本身具有的缺点：黑箱模型。可解释学习是不是说的就是要理解这个黑箱模型呢？
模型评估的查全率的公式不是特别理解。

##关于bootstrap方法：
不管是留出法还是k-fold交叉验证，都有一个问题是：用于训练的数据并不是全部的数据，而是其中的一部分，为了解决这个问题，学者提出了bootstrap方法，
即通过又放回地从所有的数据里随机挑选出与所有数据相同数据量的数据来进行训练，可以解决前面训练数据小于全部数据的缺点。但是也有个问题：这种有放回的随机挑选数据实际上会改变用于训练的数据的分布，
比如会重复挑选到一些数据，从而会使得被重复挑选到的数据的权重相比于其他数据更大了。所以bootstrap法主要用在数据量偏少的情况下。

##Attention:
![image](https://github.com/wangshuai-simulation/Note/blob/main/2025-03-11%20142335.png)
把样本空间的数据划分为训练集、验证集和测试集。训练集用来训练模型，验证集（实际上是从训练集划分出来的一部分）用于模型调参，最后用测试集来筛选模型。
筛选完模型之后再把选择的模型用训练+验证集的合并数据再训练一次，然后才会把模型交给用户使用。
说实话这个得做项目才能明白。

